<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:util="http://www.springframework.org/schema/util"
       xmlns:context="http://www.springframework.org/schema/context"
       xsi:schemaLocation="http://www.springframework.org/schema/beans
	       http://www.springframework.org/schema/beans/spring-beans.xsd
	       http://www.springframework.org/schema/util
	       http://www.springframework.org/schema/util/spring-util.xsd
	       http://www.springframework.org/schema/context
	       http://www.springframework.org/schema/context/spring-context.xsd">

    <bean id="propertyConfigurer"
          class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer">
        <property name="locations">
            <list>
                <value>classpath:es.properties</value>
            </list>
        </property>
    </bean>

    <import resource="hadoopContext.xml"/>

    <util:map id="commonJobParam" key-type="java.lang.String"
              value-type="java.lang.Object">
        <entry key="conf" value-ref="hadoopConfiguration"/>
        <entry key="fileSystem" value-ref="fileSystem"/>
        <entry key="hiveDbName" value="meiya"/>
        <entry key="esNodes" value="${es.nodes}"/>
    </util:map>

    <!-- 以下在服务器端启动时需要 -->
    <!--Spark Context Configuration -->
    <bean id="sparkContext" class="com.sdyc.ndmp.schedule.spark.SparkContextManager">
        <constructor-arg name="param">
            <util:properties location="classpath:spark.properties.back"/>
        </constructor-arg>
        <property name="idelMinuteShutdown" value="120" />
    </bean>

</beans>